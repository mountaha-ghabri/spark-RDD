{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "name": "BE4-Spark.ipynb"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mountaha-ghabri/spark-RDD/blob/main/spark_intro_rdd_tutorial_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXigF59Q-8aH"
      },
      "source": [
        "<center><img src='https://netacad.centralesupelec.fr/img/cs.jpg' width=200></center>\n",
        "\n",
        "<h6><center><b>Big data algorithms, techniques and platforms</b></center></h6>\n",
        "\n",
        "<h1>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "<center>Introduction to Spark RDD programming</center>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giAUTZyo-8aJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7ae51a-5094-48c7-a3e1-80ae7aef62cf"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [61.9 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,642 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,560 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,859 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,527 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,227 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,590 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,663 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,518 kB]\n",
            "Fetched 27.1 MB in 8s (3,306 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "tar: spark-3.1.1-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_432\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_432-8u432-ga~us1-0ubuntu2~22.04-ga)\n",
            "OpenJDK 64-Bit Server VM (build 25.432-bga, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs2LgJx675I7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe83a4e-9b6f-4038-da69-a9fe104b8b98"
      },
      "source": [
        "import pyspark\n",
        "import random\n",
        "sc = pyspark.SparkContext(appName=\"td1\")\n",
        "print(\"Initialization successful\")\n",
        "\n",
        "!wget -q https://gquercini.github.io/courses/plp/tutorials/data.tgz\n",
        "!tar xf data.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ14nYulg4oR"
      },
      "source": [
        "## Word count example\n",
        "\n",
        "Write a Spark program that reads file *./data/moby-dick.txt* and counts the number of occurrences of each word.\n",
        "The program should:\n",
        "\n",
        "- Lower case each word\n",
        "- Remove the stopwords (a list of stopwords can be found in file ./data/stopwords.txt).\n",
        "- Sort the word by their number of occurrences in decreasing order (the most frequent first).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us39LL43g4oR"
      },
      "source": [
        "stopwords = []\n",
        "with open(\"./data/stopwords.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        stopwords.append(line.lower().strip())\n",
        "\n",
        "wc_rdd = sc.textFile(\"./data/moby-dick.txt\")\\\n",
        "            .flatMap(lambda x: x.split())\\\n",
        "            .map(lambda x: x.lower())\\\n",
        "            .filter(lambda x: x not in stopwords)\\\n",
        "            .map(lambda x: (x, 1))\\\n",
        "            .reduceByKey(lambda x, y: x+y)\\\n",
        "            .sortBy(lambda x: x[1], ascending=False)\n",
        "\n",
        "\n",
        "wc_rdd.take(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWLdJsstg4oR"
      },
      "source": [
        "## Computing averages\n",
        "\n",
        "Write a Spark program that reads file *./data/temperature.csv* and computes the average temperature for each year."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whgBIDvFg4oS"
      },
      "source": [
        "temp_rdd = sc.textFile(\"./data/temperature.csv\")\\\n",
        "            .map(lambda x: x.split(\",\"))\\\n",
        "            .map(lambda x: (x[0], (float(x[2]), 1)))\\\n",
        "            .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
        "            .mapValues(lambda x: x[0]/x[1])\n",
        "\n",
        "\n",
        "temp_rdd.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5We0PyC9mt0"
      },
      "source": [
        "# Matrix operations\n",
        "\n",
        "\n",
        "Without loss of generality, we consider that our input matrices are stored\n",
        "in textual files (see folder _./data_).\n",
        "As an example, the file _./data/matrix-a.txt_ looks like as follows:\n",
        "<p>\n",
        "0 1 2 4<br>\n",
        "1 2 3 10<br>\n",
        "2 12 15 150<br>\n",
        "</p>\n",
        "</font>\n",
        "</p>\n",
        "<p>\n",
        "\n",
        "Each line is a row in a matrix $A$. The first number of the line is the\n",
        "row identifier (starting from 0), the subsequent values (separated by a whitespace)\n",
        "are the elements in each column of the row. The matrix represented in this file is the\n",
        "following:\n",
        "<p>\n",
        "<center>\n",
        "  $A= \\begin{bmatrix}\n",
        "    1 & 2 & 4   \\\\\n",
        "    2 & 3 & 10  \\\\\n",
        "    12 & 15 & 150\n",
        "\\end{bmatrix}$\n",
        "</center>\n",
        "\n",
        "\n",
        "We provide the implementation of  basic functions to load a matrix from file, visualize it\n",
        "and get attributes.\n",
        "\n",
        "* Function *loadMatrix*\n",
        "\n",
        "The function *loadMatrix()* loads a matrix from a file.\n",
        "It takes in the name of the file and returns an RDD containing the matrix.\n",
        "\n",
        "Each element of an RDD matrix is a key-value pair, where the key is the coordinate (row identifier, column identifier) of an element, and the value is the element itself.\n",
        "For instance, the RDD corresponding to the matrix $A$ is the following:\n",
        "<p>\n",
        "$( (0, 0), 1 ), ( (0, 1), 2 ), ( (0, 2), 4 ), ( (1, 0), 2 ), ( (1, 1), 3 ), ( (1, 2), 10 ), ( (2, 0), 12 ), ( (2, 1), 15 ), ( (2, 2), 150 ) $\n",
        "</p>\n",
        "\n",
        "* Function *shape*\n",
        "\n",
        "The function *shape()* takes in an RDD matrix and returns the size of the matrix as a pair $(nbRows, nbCols)$, where $nbRows$ (resp., $nbCols$) denotes the number of rows (resp., columns) of the matrix.\n",
        "\n",
        "* Function *collect*\n",
        "\n",
        "The function *collect()* takes in an RDD matrix and returns a representation of the matrix as a Python list $L$. Each element of $L$ is itself a list that corresponds to a row in the matrix.\n",
        "For instance, the output of the function $collect$ for the matrix $A$ is as follows:   \n",
        "\n",
        "\n",
        "$[ [1, 2, 4], [2, 3, 10], [12, 15, 150] ]$\n",
        "\n",
        "\n",
        "* Function *nice*\n",
        "\n",
        "The function *nice()* prints the matrix in a nice and readable way.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMmSQUo_g4oS"
      },
      "source": [
        "'''\n",
        "Loads a matrix from a file.\n",
        "Takes in: the name of the input file\n",
        "Returns: an RDD containing the matrix\n",
        "'''\n",
        "def loadMatrix(filename):\n",
        "    # Load the file into an RDD matrix\n",
        "    matrix = sc.textFile(filename)\n",
        "    # Splits each line. Each element is a list [nbRow, e1, e2, ..., ej]\n",
        "    matrix = matrix.map(lambda line : line.split(' '))\n",
        "    # Convert each element to a number (the first is an integer, the others are float)\n",
        "    matrix = matrix.map(lambda row: [int(row[0])] + [float(row[i]) for i in range(1, len(row))])\n",
        "    # Get an RDD where each element is a key-value pair ((row, col), element)\n",
        "    matrix = matrix.flatMap(lambda row: [((row[0], j-1), row[j]) for j in range(1, len(row))])\n",
        "    return matrix\n",
        "\n",
        "'''\n",
        "Returns the number of rows and colums of the matrix\n",
        "Takes in: An RDD representing a matrix\n",
        "Returns: the size of the matrix as (nbRows, nbCols)\n",
        "'''\n",
        "def shape(matrix):\n",
        "    M = collect(matrix)\n",
        "    if len(M) == 0:\n",
        "        return (0, 0)\n",
        "    else:\n",
        "        return (len(M), len(M[0]))\n",
        "\n",
        "'''\n",
        "Returns a matrix represented as a list of lists.\n",
        "Takes in: an RDD representing a matrix\n",
        "Returns: the matrix represented as a list of lists.\n",
        "'''\n",
        "def collect(matrix):\n",
        "    # Obtain an RDD, where the key is the row identifier and the value is (colId, element)\n",
        "    matrix = matrix.map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
        "    # Groups all the values in a row.\n",
        "    matrix = matrix.groupByKey()\n",
        "    # Sorts the element by row identifier.\n",
        "    matrix = matrix.sortByKey()\n",
        "    # Sort the elements by column identifier.\n",
        "    matrix = matrix.map(lambda x: sorted(list(x[1])))\n",
        "    # Now obtain an RDD, where each element is a list containing the elements of a row.\n",
        "    matrix = matrix.map(lambda row: [x[1] for x in row])\n",
        "    # Finally, return the RDD as a Python list.\n",
        "    return matrix.collect()\n",
        "\n",
        "'''\n",
        "Prints the matrix in a nice way.\n",
        "Takes in: the name of the matrix (var) and the matrix in the form of an RDD.\n",
        "'''\n",
        "def nice(var, matrix):\n",
        "    # Obtain a representation of the matrix as a Python list.\n",
        "    M = collect(matrix)\n",
        "    # Print the name of the matrix\n",
        "    print(\"Matrix \", var)\n",
        "    # Print the matrix and format the output nicely\n",
        "    print('\\n'.join([''.join(['{:12.2f}'.format(item) for item in row])\n",
        "      for row in M]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMerMXtYB9qd"
      },
      "source": [
        "## Data creation\n",
        "\n",
        "Execute the following cells in order to create two files, one containing matrix $A$, the other containing matrix $B$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKMvLL5zB9RS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4644c4c9-c2bd-4ca1-f9f0-89f3e7f86bae"
      },
      "source": [
        "%%file ./data/matrix-a.txt\n",
        "0 1 2 4\n",
        "1 2 3 10\n",
        "2 12 15 150"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ./data/matrix-a.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFhBeAECWk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8b1cdb-bf13-4811-dd3c-8a42df1f817e"
      },
      "source": [
        "%%file ./data/matrix-b.txt\n",
        "0 4 2 2\n",
        "1 1 3 3\n",
        "2 23 34 12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ./data/matrix-b.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7l65IH2-jNr"
      },
      "source": [
        "## Sum of matrices\n",
        "\n",
        "The code below loads two matrices $A$ and $B$ from file and calls the function $sum()$ to compute $A+B$.\n",
        "\n",
        "The function $sum()$ takes in:\n",
        "\n",
        "* $A$: an RDD containing the first matrix.\n",
        "* $B$: an RDD containing the second matrix.\n",
        "\n",
        "The function *sum()* returns an RDD containing the matrix obtained by summing $A$ and $B$.\n",
        "\n",
        "**Complete the definition of the function $sum()$ and execute the code**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV2paFgm-TcQ"
      },
      "source": [
        "'''\n",
        "Computes the sum of two matrices.\n",
        "Takes in: two RDDs containing the input matrices\n",
        "Returns: the RDD containing the sum of the two input matrices\n",
        "'''\n",
        "def sum(A, B):\n",
        "  # COMPLETE THIS FUNCTION\n",
        "  return A.join(B).mapValues(lambda x: x[0] + x[1])\n",
        "\n",
        "# Load matrix A from file and print it.\n",
        "A = loadMatrix(\"./data/matrix-a.txt\")\n",
        "nice(\"A\", A)\n",
        "\n",
        "# Load matrix B from file and print it.\n",
        "B = loadMatrix(\"./data/matrix-b.txt\")\n",
        "nice(\"B\", B)\n",
        "\n",
        "# Compute A+B and print it\n",
        "C = sum(A, B)\n",
        "nice(\"C\", C)\n",
        "\n",
        "##############################################################\n",
        "#YOU SHOULD OBTAIN THE FOLLOWING MATRIX C AS RESULT\n",
        "# 5.00        4.00        6.00\n",
        "# 3.00        6.00       13.00\n",
        "# 35.00       49.00      162.00\n",
        "##############################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCODbqOB-1Fq"
      },
      "source": [
        "## Scalar multiplication\n",
        "\n",
        "The code below calls the function *scalarMultiply()* to obtain the matrix $c\\times A$, where $c$ is a scalar value.    \n",
        "\n",
        "The function *scalarMultiply()* takes in:\n",
        "\n",
        "* $c$: a scalar value.\n",
        "* $M$: an RDD containing a matrix.\n",
        "\n",
        "The function *scalarMultiply()* returns an RDD containing the matrix obtained by multiplying $c$ with the input matrix.\n",
        "\n",
        "\n",
        "**Complete the definition of the function scalarMultiply() and execute the code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F85nu51a-8sS"
      },
      "source": [
        "'''\n",
        "Computes the scalar multiplication.\n",
        "Takes in a scalar value c and an RDD matrix M\n",
        "Returns the RDD containing the matrix resulting from the scalar multiplication c * M.\n",
        "'''\n",
        "def scalarMultiply(c, M):\n",
        "    # COMPLETE THIS FUNCTION\n",
        "    R = M.mapValues(lambda e: e*c)\n",
        "    return R\n",
        "\n",
        "# Print the input and the output\n",
        "nice(\"A\", A)\n",
        "nice(\"2*A\", scalarMultiply(2, A))\n",
        "\n",
        "##############################################################\n",
        "# THE RESULT SHOULD BE\n",
        "#2.00        4.00        8.00\n",
        "#4.00        6.00       20.00\n",
        "#24.00       30.00      300.00\n",
        "##############################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e0s_y3LCdvi"
      },
      "source": [
        "## Matrix multiplication\n",
        "\n",
        "We create a new matrix B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMMQ0C389QKH"
      },
      "source": [
        "%%file ./data/matrix-b.txt\n",
        "0 4 2 2 324 23\n",
        "1 1 3 3 333 423\n",
        "2 23 34 12 12 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz011jM--zKX"
      },
      "source": [
        "**Complete the function multiply that multiplies matrix A and B**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWGK1WYrCw9I"
      },
      "source": [
        "def multiply(A, B):\n",
        "  # lambda ((i, j), v): (j, (i, v))\n",
        "  left = A.map(lambda e: (e[0][1], (e[0][0], e[1])))\n",
        "  # lambda ((j, k), w): (j, (k, w))\n",
        "  right = B.map(lambda e: (e[0][0], (e[0][1], e[1])))\n",
        "  productEntries = left.join(right)\n",
        "  # lambda (x, ((i, v), (k, w))): ((i, k), (v * w))\n",
        "  productEntries = productEntries.map(lambda e: ( (e[1][0][0], e[1][1][0]), (e[1][0][1] * e[1][1][1]) ) )\\\n",
        "                  .reduceByKey(lambda x,y: x+y)\n",
        "  return productEntries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pu1sSyUgqAu"
      },
      "source": [
        "def multiply(A, B):\n",
        "  # lambda ((i, j), v): (j, (i, v))\n",
        "  left = A.map(lambda e: (e[0][1], (e[0][0], e[1])))\n",
        "  # lambda ((j, k), w): (j, (k, w))\n",
        "  right = B.map(lambda e: (e[0][0], (e[0][1], e[1])))\n",
        "  productEntries = left.join(right)\n",
        "  # lambda (x, ((i, v), (k, w))): ((i, k), (v * w))\n",
        "  productEntries = productEntries.map(lambda e: ( (e[1][0][0], e[1][1][0]), (e[1][0][1] * e[1][1][1]) ) )\\\n",
        "                  .reduceByKey(lambda x,y: x+y)\n",
        "  return productEntries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Z3ovTz_A8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe34414-621a-4e84-a462-87cd40e02673"
      },
      "source": [
        "# Load matrix A from file and print it.\n",
        "A = loadMatrix(\"./data/matrix-a.txt\")\n",
        "nice(\"A\", A)\n",
        "\n",
        "# Load matrix B from file and print it.\n",
        "B = loadMatrix(\"./data/matrix-b.txt\")\n",
        "nice(\"B\", B)\n",
        "\n",
        "# Compute A+B and print it\n",
        "C = multiply(A, B)\n",
        "nice(\"C\", C)\n",
        "\n",
        "##############################################################\n",
        "#YOU SHOULD OBTAIN THE FOLLOWING MATRIX C AS RESULT\n",
        "# 98.00      144.00       56.00\n",
        "# 241.00      353.00      133.00\n",
        "# 3513.00     5169.00     1869.00\n",
        "##############################################################\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix  A\n",
            "        1.00        2.00        4.00\n",
            "        2.00        3.00       10.00\n",
            "       12.00       15.00      150.00\n",
            "Matrix  B\n",
            "        4.00        2.00        2.00\n",
            "        1.00        3.00        3.00\n",
            "       23.00       34.00       12.00\n",
            "Matrix  C\n",
            "       98.00      144.00       56.00\n",
            "      241.00      353.00      133.00\n",
            "     3513.00     5169.00     1869.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOqoOXZXF_fg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}